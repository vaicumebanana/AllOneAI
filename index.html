<!DOCTYPE html>
<html>
<head>
    <title>AllOneAI - Modelos de IA</title>
    <style>
        body {
            background-color: green;
        }
    </style>
</head>
<body>
    <h1>AllOneAI</h1>
    <p>Principais modelos de IA em um único lugar</p>

    <div>
        <h3>Chat</h3>
        <div id="chat-history">
            <p>Olá! Escolha um modelo abaixo e comece a conversar!</p>
        </div>
        <input type="text" id="user-input" placeholder="Digite sua mensagem...">
        <button id="send-button">Enviar</button>
    </div>

    <div>
        <h3>Selecione o Modelo</h3>
        <select id="model-selector">
            <option value="">-- Selecione --</option>
            <option value="openrouter:openai/gpt-4o">GPT-4o (OpenAI)</option>
            <option value="openrouter:anthropic/claude-3-opus">Claude 3 Opus (Anthropic)</option>
            <option value="openrouter:google/gemini-2.5-pro">Gemini 2.5 Pro (Google)</option>
            <option value="openrouter:meta-llama/llama-3-70b-instruct">Llama 3 70B (Meta)</option>
            <option value="openrouter:mistralai/mistral-large">Mistral Large (Mistral)</option>
        </select>
        <div id="model-info">Selecione um modelo para ver sua descrição</div>
    </div>

    <div id="loading" style="display:none">Processando...</div>

    <script src="https://js.puter.com/v2/"></script>
    <script>
        const models = {
            "openrouter:openai/gpt-4o": {
                name: "GPT-4o",
                description: "Modelo mais avançado da OpenAI"
            },
            "openrouter:anthropic/claude-3-opus": {
                name: "Claude 3 Opus", 
                description: "Modelo topo de linha da Anthropic"
            },
            "openrouter:google/gemini-2.5-pro": {
                name: "Gemini 2.5 Pro",
                description: "Modelo avançado do Google"
            },
            "openrouter:meta-llama/llama-3-70b-instruct": {
                name: "Llama 3 70B",
                description: "Modelo open-source da Meta"
            },
            "openrouter:mistralai/mistral-large": {
                name: "Mistral Large",
                description: "Modelo avançado da Mistral AI"
            }
        };

        let currentModel = "";
        let currentConversation = [];

        // Carregar conversa salva ao iniciar
        function loadConversation() {
            const savedConversation = localStorage.getItem('aiConversation');
            if (savedConversation) {
                currentConversation = JSON.parse(savedConversation);
                // Reconstruir o chat a partir do localStorage
                document.getElementById('chat-history').innerHTML = '';
                currentConversation.forEach(msg => {
                    addMessage(msg.content, msg.role === 'user' ? 'user' : 'ai', false);
                });
            }
        }

        // Salvar conversa no localStorage
        function saveConversation() {
            localStorage.setItem('aiConversation', JSON.stringify(currentConversation));
        }

        // Inicialização
        document.addEventListener('DOMContentLoaded', function() {
            loadConversation();
            
            document.getElementById('model-selector').addEventListener('change', function() {
                currentModel = this.value;
                const model = models[currentModel];
                document.getElementById('model-info').innerHTML = model 
                    ? `<b>${model.name}</b>: ${model.description}`
                    : "Selecione um modelo";
                
                if (currentConversation.length === 0 && model) {
                    addMessage(`Você está conversando com ${model.name}. Como posso ajudar?`, 'ai');
                }
            });

            document.getElementById('send-button').addEventListener('click', sendMessage);
            document.getElementById('user-input').addEventListener('keypress', function(e) {
                if (e.key === 'Enter') sendMessage();
            });
        });

        function sendMessage() {
            const input = document.getElementById('user-input');
            const message = input.value.trim();
            if (!message || !currentModel) return;

            addMessage(message, 'user');
            input.value = '';
            document.getElementById('loading').style.display = 'block';
            currentConversation.push({role: 'user', content: message});

            puter.ai.chat(currentConversation, {model: currentModel})
                .then(response => {
                    addMessage(response, 'ai');
                    currentConversation.push({role: 'assistant', content: response});
                    saveConversation(); // Salvar após resposta da IA
                })
                .catch(err => {
                    addMessage("Erro: " + err.message, 'ai');
                })
                .finally(() => {
                    document.getElementById('loading').style.display = 'none';
                });
        }

        function addMessage(text, sender, save = true) {
            const chat = document.getElementById('chat-history');
            const msg = document.createElement('p');
            msg.textContent = (sender === 'user' ? "Você: " : "IA: ") + text;
            chat.appendChild(msg);
            chat.scrollTop = chat.scrollHeight;
            
            if (save) {
                saveConversation();
            }
        }
    </script>
</body>
</html>
